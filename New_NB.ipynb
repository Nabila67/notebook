{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New NB.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNeQ3B/yMN4TbQO3vh66A/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nabila67/notebook/blob/master/New_NB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gev-9hfnf6A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a8161444-000f-439b-b2ed-8fce377a876c"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnRcJiPNXZrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "425f53d7-4f45-4913-c965-a4b44f8a999a"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "print(x)\n",
        "y = torch.rand(2,2)\n",
        "print(y)\n",
        "z =torch.add(x,y)\n",
        "print(z)\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9991, 0.7053],\n",
            "        [0.1906, 0.3459]])\n",
            "tensor([[0.2622, 0.0574],\n",
            "        [0.4363, 0.9464]])\n",
            "tensor([[1.2612, 0.7627],\n",
            "        [0.6269, 1.2922]])\n",
            "tensor([[1.2612, 0.7627],\n",
            "        [0.6269, 1.2922]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcsta4Kgheh2",
        "colab_type": "text"
      },
      "source": [
        "### **Reshape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZkAhhLsg9bA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8824a3ec-ab15-460f-fa6c-8b47bb1a2ac3"
      },
      "source": [
        "x = torch.rand(4,4)\n",
        "print(x)\n",
        "y = x.view(-1,8)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6156, 0.0028, 0.5508, 0.8821],\n",
            "        [0.2013, 0.2663, 0.9730, 0.1969],\n",
            "        [0.0185, 0.5829, 0.1577, 0.3530],\n",
            "        [0.4594, 0.7213, 0.9781, 0.7540]])\n",
            "tensor([[0.6156, 0.0028, 0.5508, 0.8821, 0.2013, 0.2663, 0.9730, 0.1969],\n",
            "        [0.0185, 0.5829, 0.1577, 0.3530, 0.4594, 0.7213, 0.9781, 0.7540]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibrJpBUBhcuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHYYkan4h60Y",
        "colab_type": "text"
      },
      "source": [
        "## **confert tensor to numpy and veseverse**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfkm-VIbiE6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e0a9d36f-0265-4bde-e42b-522542ca6414"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = torch.ones(5)\n",
        "print(x)\n",
        "y = x.numpy()\n",
        "print(type(y))\n",
        "x.add_(1)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsNwVl0xnMJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "635e4bd4-1e85-4426-988f-586ef971337b"
      },
      "source": [
        "x = np.ones(5)\n",
        "print(x)\n",
        "y = torch.from_numpy(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD-ESOSos-lZ",
        "colab_type": "text"
      },
      "source": [
        "### Gradient descent "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3HfTSkxs8l9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "8561b027-7504-4f45-de4a-1aff6367c183"
      },
      "source": [
        "import torch\n",
        "x = torch.randn(3,requires_grad= True)\n",
        "print(x)\n",
        "y = x+2\n",
        "print(y)\n",
        "z= y*y*2\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "z.backward()\n",
        "v = torch.tensor([1,2,3],dtype=torch.float32)\n",
        "z = backward(v)\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.8763,  1.1708,  0.8672], requires_grad=True)\n",
            "tensor([1.1237, 3.1708, 2.8672], grad_fn=<AddBackward0>)\n",
            "tensor([ 2.5253, 20.1079, 16.4420], grad_fn=<MulBackward0>)\n",
            "tensor(13.0251, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-21f44384cc32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'backward' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U9H4lAvx4mpK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "055444f3-b2f1-4247-89aa-6ffa8a58408f"
      },
      "source": [
        "import torch\n",
        "# y= wx, start by y = 2, x = 1, w = 1\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0,requires_grad=True)\n",
        "y_hat = w*x\n",
        "loss = (y_hat-y)**2\n",
        "print(loss)\n",
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDjT4gVlnByN",
        "colab_type": "text"
      },
      "source": [
        "### input - output and weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVZZE6Igl8sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCCtBtVqaz7t",
        "colab_type": "text"
      },
      "source": [
        "### Example of Gradient desent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFlvJDWjnVQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "368e7374-9f61-499f-ef4e-7035a71d7ce2"
      },
      "source": [
        "\n",
        "import numpy as np \n",
        "\n",
        "# Compute every step manually\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x \n",
        "\n",
        "# here : f = 2 * x\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "# J = MSE = 1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N * 2x(w*x - y)\n",
        "def gradient(x, y, y_pred):\n",
        "    return np.dot(2*x, y_pred - y).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "   \n",
        "    \n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "    \n",
        "    # calculate gradients\n",
        "    dw = gradient(X, Y, y_pred)\n",
        "\n",
        "    # update weights\n",
        "    w -= learning_rate * dw\n",
        "\n",
        "    if epoch % 2 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "     \n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 1.200, loss = 30.00000000\n",
            "epoch 3: w = 1.872, loss = 0.76800019\n",
            "epoch 5: w = 1.980, loss = 0.01966083\n",
            "epoch 7: w = 1.997, loss = 0.00050331\n",
            "epoch 9: w = 1.999, loss = 0.00001288\n",
            "epoch 11: w = 2.000, loss = 0.00000033\n",
            "epoch 13: w = 2.000, loss = 0.00000001\n",
            "epoch 15: w = 2.000, loss = 0.00000000\n",
            "epoch 17: w = 2.000, loss = 0.00000000\n",
            "epoch 19: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT2r88d_y_PV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "e7c5187a-b806-4ed6-a5ac-ab3afda8f19a"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Compute every step manually\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x \n",
        "\n",
        "# here : f = 2 * x\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "\n",
        "# gradient\n",
        "\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "   \n",
        "    \n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "    \n",
        "    # calculate gradients\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    with torch.no_grad():\n",
        "      w -= learning_rate * w.grad\n",
        "\n",
        "    w.grad.zero_() \n",
        "    if epoch % 2 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "     \n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 3: w = 0.772, loss = 15.66018772\n",
            "epoch 5: w = 1.113, loss = 8.17471695\n",
            "epoch 7: w = 1.359, loss = 4.26725292\n",
            "epoch 9: w = 1.537, loss = 2.22753215\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 13: w = 1.758, loss = 0.60698116\n",
            "epoch 15: w = 1.825, loss = 0.31684780\n",
            "epoch 17: w = 1.874, loss = 0.16539653\n",
            "epoch 19: w = 1.909, loss = 0.08633806\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 23: w = 1.952, loss = 0.02352631\n",
            "epoch 25: w = 1.966, loss = 0.01228084\n",
            "epoch 27: w = 1.975, loss = 0.00641066\n",
            "epoch 29: w = 1.982, loss = 0.00334642\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 33: w = 1.991, loss = 0.00091188\n",
            "epoch 35: w = 1.993, loss = 0.00047601\n",
            "epoch 37: w = 1.995, loss = 0.00024848\n",
            "epoch 39: w = 1.996, loss = 0.00012971\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 43: w = 1.998, loss = 0.00003534\n",
            "epoch 45: w = 1.999, loss = 0.00001845\n",
            "epoch 47: w = 1.999, loss = 0.00000963\n",
            "epoch 49: w = 1.999, loss = 0.00000503\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 53: w = 2.000, loss = 0.00000137\n",
            "epoch 55: w = 2.000, loss = 0.00000071\n",
            "epoch 57: w = 2.000, loss = 0.00000037\n",
            "epoch 59: w = 2.000, loss = 0.00000019\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 63: w = 2.000, loss = 0.00000005\n",
            "epoch 65: w = 2.000, loss = 0.00000003\n",
            "epoch 67: w = 2.000, loss = 0.00000001\n",
            "epoch 69: w = 2.000, loss = 0.00000001\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 73: w = 2.000, loss = 0.00000000\n",
            "epoch 75: w = 2.000, loss = 0.00000000\n",
            "epoch 77: w = 2.000, loss = 0.00000000\n",
            "epoch 79: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 83: w = 2.000, loss = 0.00000000\n",
            "epoch 85: w = 2.000, loss = 0.00000000\n",
            "epoch 87: w = 2.000, loss = 0.00000000\n",
            "epoch 89: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "epoch 93: w = 2.000, loss = 0.00000000\n",
            "epoch 95: w = 2.000, loss = 0.00000000\n",
            "epoch 97: w = 2.000, loss = 0.00000000\n",
            "epoch 99: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}